import Constants from 'expo-constants';
import { addSafetyInstructions } from './aiSafety';

// Get the API key from the app configuration
const API_KEY = Constants.expoConfig?.extra?.geminiApiKey;

// Gemini 2.5 Pro Model API URL (supports multimodal including audio)
const GEMINI_AUDIO_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent';

// TTS API URLs
const GEMINI_2_5_TTS_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-tts:generateContent?key=${API_KEY}`;
const GOOGLE_TTS_URL = `https://texttospeech.googleapis.com/v1/text:synthesize?key=${API_KEY}`;

/**
 * Converts audio file to base64 string
 * @param {string} audioUri - URI of the audio file
 * @returns {Promise<string>} Base64 encoded audio data
 */
export const audioToBase64 = async (audioUri) => {
  try {
    const response = await fetch(audioUri);
    const blob = await response.blob();
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        const base64 = reader.result.split(',')[1]; // Remove data:audio/wav;base64, prefix
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  } catch (error) {
    console.error('Audio to base64 conversion error:', error);
    throw error;
  }
};

/**
 * Sends audio message or text to Gemini 2.5 Pro model for voice conversation
 * @param {string} audioUri - URI of the recorded audio file (optional if textInput provided)
 * @param {string} conversationContext - Context about the conversation (goal setting, report, etc.)
 * @param {string} step - Current step in the conversation
 * @param {string} textInput - Text input (optional if audioUri provided)
 * @returns {Promise<{text: string, audio?: string}>} AI response with text and optional audio
 */
export const sendAudioMessage = async (audioUri, conversationContext, step, textInput = null) => {
  if (!API_KEY) {
    console.error('API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê³  ì•±ì„ ë‹¤ì‹œ ì‹œì‘í•˜ì„¸ìš”.');
    return {
      text: 'API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.',
      error: true
    };
  }

  if (!audioUri && !textInput) {
    console.error('ì „ì†¡í•  ì˜¤ë””ì˜¤ë‚˜ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.');
    return {
      text: 'ìŒì„±ì´ë‚˜ í…ìŠ¤íŠ¸ ì…ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.',
      error: true
    };
  }

  try {
    console.log('Gemini 2.5 Pro ëª¨ë¸ì— ë©”ì‹œì§€ ì „ì†¡ ì¤‘...');

    const parts = [
      {
        text: addSafetyInstructions(getConversationPrompt(conversationContext, step))
      }
    ];

    // Add audio if provided
    if (audioUri) {
      const audioBase64 = await audioToBase64(audioUri);
      parts.push({
        inlineData: {
          mimeType: "audio/wav",
          data: audioBase64
        }
      });
    }

    // Add text input if provided
    if (textInput) {
      parts.push({
        text: `ì‚¬ìš©ì ì…ë ¥: ${textInput}`
      });
    }

    const requestData = {
      contents: [
        {
          role: "user",
          parts: parts
        }
      ],
      generationConfig: {
        maxOutputTokens: 8192,
        temperature: 0.7,
      }
    };

    const response = await fetch(`${GEMINI_AUDIO_API_URL}?key=${API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestData)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('API ì‘ë‹µ ì˜¤ë¥˜:', response.status, errorText);
      throw new Error(`API ìš”ì²­ ì‹¤íŒ¨: ${response.status}`);
    }

    const data = await response.json();
    console.log('Gemini 2.5 Native Audio ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.');

    const aiResponse = data.candidates?.[0]?.content?.parts?.[0]?.text;
    if (aiResponse) {
      return {
        text: aiResponse,
        error: false
      };
    } else {
      console.error('ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜:', data);
      return {
        text: 'ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
        error: true
      };
    }

  } catch (error) {
    console.error('ìŒì„± ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    return {
      text: `ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`,
      error: true
    };
  }
};

/**
 * Gets conversation prompt based on context and step
 * @param {string} context - Conversation context ('goal-setting', 'daily-report', 'weekly-report')
 * @param {string} step - Current step in the conversation
 * @returns {string} Conversation prompt
 */
const getConversationPrompt = (context, step) => {
  const basePrompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŠµê´€ ê´€ë¦¬ì™€ ëª©í‘œ ë‹¬ì„±ì„ ë•ëŠ” ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ AI ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì‘ë‹µì€ í•œêµ­ì–´ë¡œ í•˜ë©°, ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.";

  switch (context) {
    case 'goal-setting':
      return getGoalSettingPrompt(step);
    case 'daily-report':
      return getDailyReportPrompt(step);
    case 'weekly-report':
      return getWeeklyReportPrompt(step);
    default:
      return basePrompt;
  }
};

/**
 * Goal setting conversation prompts
 */
const getGoalSettingPrompt = (step) => {
  const prompts = {
    'step1': `
      ${getBasePrompt()}
      
      í˜„ì¬ ì‚¬ìš©ìì™€ ëª©í‘œ ì„¤ì • ëŒ€í™”ë¥¼ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ë¡œ, ì‚¬ìš©ìê°€ ì´ë£¨ê³  ì‹¶ì€ ìŠµê´€ì´ë‚˜ ëª©í‘œê°€ ë¬´ì—‡ì¸ì§€ ì•Œì•„ë³´ë ¤ê³  í•©ë‹ˆë‹¤.
      
      ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
      1. ì‚¬ìš©ìê°€ ë§í•œ ëª©í‘œë‚˜ ìŠµê´€ì„ íŒŒì•…í•´ì£¼ì„¸ìš”
      2. êµ¬ì²´ì ì´ì§€ ì•Šë‹¤ë©´ ë” ëª…í™•í•˜ê²Œ í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”
      3. ê¸ì •ì ì´ê³  ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”
      4. ë‹¤ìŒ ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•´ì£¼ì„¸ìš” (ì‹œê°„ëŒ€, ê¸°ê°„ ë“±)
      
      ì‘ë‹µ ê¸¸ì´: 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    `,
    'step2': `
      ${getBasePrompt()}
      
      ëª©í‘œ ì„¤ì •ì˜ ë‘ ë²ˆì§¸ ë‹¨ê³„ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìŠµê´€ ì‹¤í–‰ ì‹œê°„ê³¼ í”„ë¡œì íŠ¸ ê¸°ê°„ì— ëŒ€í•´ ì•Œì•„ë³´ë ¤ê³  í•©ë‹ˆë‹¤.
      
      ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
      1. ì–¸ì œ ì´ ìŠµê´€ì„ ì‹¤í–‰í•˜ê³  ì‹¶ì€ì§€ (ì‹œê°„ëŒ€)
      2. ì–¼ë§ˆë‚˜ ì˜¤ë«ë™ì•ˆ ì§„í–‰í•˜ê³  ì‹¶ì€ì§€ (ê¸°ê°„)
      3. í•˜ë£¨ì— ì–¼ë§ˆë‚˜ ì‹œê°„ì„ íˆ¬ìí•  ìˆ˜ ìˆëŠ”ì§€
      
      ì´ ì •ë³´ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¡œ ì•Œì•„ë‚´ì£¼ì„¸ìš”.
      
      ì‘ë‹µ ê¸¸ì´: 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    `,
    'step3': `
      ${getBasePrompt()}
      
      ëª©í‘œ ì„¤ì •ì˜ ì„¸ ë²ˆì§¸ ë‹¨ê³„ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ì–´ë ¤ì›Œí•˜ëŠ” ì´ìœ ë‚˜ ì¥ì• ë¬¼ì— ëŒ€í•´ ì•Œì•„ë³´ë ¤ê³  í•©ë‹ˆë‹¤.
      
      ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
      1. ì´ì „ì— ë¹„ìŠ·í•œ ëª©í‘œë¥¼ ì‹œë„í–ˆì„ ë•Œ ì–´ë ¤ì› ë˜ ì 
      2. í˜„ì¬ ì˜ˆìƒë˜ëŠ” ì¥ì• ë¬¼ì´ë‚˜ ì–´ë ¤ì›€
      3. ë™ê¸° ë¶€ì¡±, ì‹œê°„ ë¶€ì¡±, í™˜ê²½ì  ìš”ì¸ ë“±ì„ íŒŒì•…í•´ì£¼ì„¸ìš”
      
      ê³µê°í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ë©°, ì´ëŸ° ì–´ë ¤ì›€ì€ ìì—°ìŠ¤ëŸ¬ìš´ ê²ƒì„ì„ ì•Œë ¤ì£¼ì„¸ìš”.
      
      ì‘ë‹µ ê¸¸ì´: 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    `,
    'summary': `
      ${getBasePrompt()}
      
      ëª©í‘œ ì„¤ì • ëŒ€í™”ê°€ ê±°ì˜ ë§ˆë¬´ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ëŒ€í™”í•œ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì‚¬ìš©ìë¥¼ ê²©ë ¤í•´ì£¼ì„¸ìš”.
      
      ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
      1. ìµœì¢… í™•ì¸ì´ë‚˜ ì¶”ê°€ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”
      2. ëª©í‘œ ë‹¬ì„±ì— ëŒ€í•œ ê¸ì •ì ì¸ ì „ë§ì„ ì œì‹œí•´ì£¼ì„¸ìš”
      3. AIê°€ í•¨ê»˜ ë„ì™€ì¤„ ê²ƒì„ì„ ì•½ì†í•´ì£¼ì„¸ìš”
      
      ì‘ë‹µ ê¸¸ì´: 3-4ë¬¸ì¥ìœ¼ë¡œ ê²©ë ¤í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”.
    `
  };

  return prompts[step] || prompts['step1'];
};

/**
 * Daily report conversation prompts
 */
const getDailyReportPrompt = (step) => {
  const prompts = {
    'reflection': `
      ${getBasePrompt()}
      
      ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë³´ëŠ” ì¼ê°„ ë¦¬í¬íŠ¸ ì‘ì„±ì„ ë„ì™€ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
      
      ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
      1. ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë–»ê²Œ ë³´ëƒˆëŠ”ì§€
      2. ëª©í‘œí•œ ì¼ë“¤ì„ ì–¼ë§ˆë‚˜ ë‹¬ì„±í–ˆëŠ”ì§€
      3. ê¸°ë¶„ì´ë‚˜ ì»¨ë””ì…˜ì€ ì–´ë• ëŠ”ì§€
      4. ì–´ë ¤ì› ë˜ ì ì´ë‚˜ ì˜í•œ ì ì€ ë¬´ì—‡ì¸ì§€
      
      ë”°ëœ»í•˜ê³  ê³µê°í•˜ëŠ” í†¤ìœ¼ë¡œ ì‚¬ìš©ìì˜ í•˜ë£¨ë¥¼ ë“¤ì–´ì£¼ì„¸ìš”. íŒë‹¨í•˜ì§€ ë§ê³  ë¨¼ì € ë“¤ì–´ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
      
      ì‘ë‹µ ê¸¸ì´: 2-3ë¬¸ì¥ìœ¼ë¡œ ê³µê°í•˜ë©° ì¶”ê°€ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
    `,
    'feedback': `
      ${getBasePrompt()}
      
      ì‚¬ìš©ìì˜ í•˜ë£¨ ì´ì•¼ê¸°ë¥¼ ë“¤ì—ˆìœ¼ë‹ˆ, ì´ì œ ê²©ë ¤ì™€ ì¡°ì–¸ì„ ì œê³µí•  ì°¨ë¡€ì…ë‹ˆë‹¤.
      
      ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
      1. ì˜¤ëŠ˜ì˜ ì„±ê³¼ë¥¼ ì¸ì •í•˜ê³  ì¹­ì°¬í•´ì£¼ì„¸ìš”
      2. ì–´ë ¤ì› ë˜ ì ì— ëŒ€í•´ ê³µê°í•´ì£¼ì„¸ìš”  
      3. ë‚´ì¼ì„ ìœ„í•œ ê°„ë‹¨í•œ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”
      4. ê¸ì •ì ì¸ ë§ˆë¬´ë¦¬ë¡œ ë™ê¸°ë¶€ì—¬í•´ì£¼ì„¸ìš”
      
      ì‘ë‹µ ê¸¸ì´: 3-4ë¬¸ì¥ìœ¼ë¡œ ë”°ëœ»í•œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
    `
  };

  return prompts[step] || prompts['reflection'];
};

/**
 * Weekly report conversation prompts
 */
const getWeeklyReportPrompt = (step) => {
  return `
    ${getBasePrompt()}
    
    ì´ë²ˆ ì£¼ë¥¼ ëŒì•„ë³´ëŠ” ì£¼ê°„ ë¦¬í¬íŠ¸ ì‘ì„±ì„ ë„ì™€ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
    
    ì‚¬ìš©ìì˜ ìŒì„±ì„ ë“£ê³ :
    1. ì´ë²ˆ ì£¼ ì „ì²´ì ì¸ ëª©í‘œ ë‹¬ì„±ë„ëŠ” ì–´ë• ëŠ”ì§€
    2. ê°€ì¥ ì˜í•œ ì¼ê³¼ ì•„ì‰¬ì› ë˜ ì¼
    3. ë‹¤ìŒ ì£¼ì—ëŠ” ì–´ë–»ê²Œ ê°œì„ í•˜ê³  ì‹¶ì€ì§€
    4. ìƒˆë¡œìš´ ê³„íšì´ë‚˜ ì¡°ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„
    
    ì¼ì£¼ì¼ì´ë¼ëŠ” ê¸´ ê¸°ê°„ì„ ëŒì•„ë³´ëŠ” ë§Œí¼, ë” í° ê·¸ë¦¼ì—ì„œ ê²©ë ¤ì™€ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.
    
    ì‘ë‹µ ê¸¸ì´: 3-4ë¬¸ì¥ìœ¼ë¡œ ë”°ëœ»í•˜ê³  í†µì°°ë ¥ ìˆëŠ” í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
  `;
};

/**
 * Base prompt for all conversations
 */
const getBasePrompt = () => {
  return "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŠµê´€ ê´€ë¦¬ì™€ ëª©í‘œ ë‹¬ì„±ì„ ë•ëŠ” ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ AI ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì‘ë‹µì€ í•œêµ­ì–´ë¡œ í•˜ë©°, ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.";
};

/**
 * Gemini 2.5 Pro ëª¨ë¸ì—ì„œ ìŒì„± ì¶œë ¥ê³¼ í•¨ê»˜ ì‘ë‹µì„ ìƒì„±
 * @param {string} audioUri - URI of the recorded audio file (optional if textInput provided)
 * @param {string} conversationContext - Context about the conversation
 * @param {string} step - Current step in the conversation
 * @param {string} textInput - Text input (optional if audioUri provided)
 * @param {boolean} requestAudio - Whether to request audio output from Gemini
 * @returns {Promise<{text: string, audioData?: string, audioUrl?: string}>} AI response with text and optional audio
 */
export const sendAudioMessageWithVoice = async (audioUri, conversationContext, step, textInput = null, requestAudio = true) => {
  if (!API_KEY) {
    console.error('API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.');
    return {
      text: 'API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
      error: true
    };
  }

  if (!audioUri && !textInput) {
    return {
      text: 'ìŒì„±ì´ë‚˜ í…ìŠ¤íŠ¸ ì…ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.',
      error: true
    };
  }

  try {
    console.log('Gemini 2.5 Pro ëª¨ë¸ì— ìŒì„± ì¶œë ¥ ìš”ì²­ ì¤‘...');

    const parts = [
      {
        text: addSafetyInstructions(getConversationPrompt(conversationContext, step))
      }
    ];

    // Add audio if provided
    if (audioUri) {
      const audioBase64 = await audioToBase64(audioUri);
      parts.push({
        inlineData: {
          mimeType: "audio/wav",
          data: audioBase64
        }
      });
    }

    // Add text input if provided
    if (textInput) {
      parts.push({
        text: `ì‚¬ìš©ì ì…ë ¥: ${textInput}`
      });
    }

    // ìŒì„± ì¶œë ¥ ìš”ì²­ ì¶”ê°€
    if (requestAudio) {
      parts.push({
        text: "ì‘ë‹µì„ í•œêµ­ì–´ ìŒì„±ìœ¼ë¡œë„ ì œê³µí•´ì£¼ì„¸ìš”. ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë§í•´ì£¼ì„¸ìš”."
      });
    }

    const requestData = {
      contents: [
        {
          role: "user",
          parts: parts
        }
      ],
      generationConfig: {
        maxOutputTokens: 8192,
        temperature: 0.7
      }
    };

    // Gemini 2.5 Flash Native Audio ì‹œë„ (í˜„ì¬ ì œí•œì  ì§€ì›)
    // if (requestAudio) {
    //   requestData.generationConfig.responseModalities = ["TEXT", "AUDIO"];
    //   console.log('Gemini 2.5 Flash ë„¤ì´í‹°ë¸Œ ì˜¤ë””ì˜¤ ìš”ì²­ ì¤‘...');
    // }
    
    // í˜„ì¬ëŠ” í…ìŠ¤íŠ¸ë§Œ ìš”ì²­í•˜ê³  Web TTSë¡œ ì²˜ë¦¬
    console.log('Gemini 2.5 Flash í…ìŠ¤íŠ¸ ì‘ë‹µ ìš”ì²­ ì¤‘... (ì˜¤ë””ì˜¤ëŠ” Web TTSë¡œ ì²˜ë¦¬)');

    const response = await fetch(`${GEMINI_AUDIO_API_URL}?key=${API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestData)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('API ì‘ë‹µ ì˜¤ë¥˜:', response.status, errorText);
      throw new Error(`API ìš”ì²­ ì‹¤íŒ¨: ${response.status}`);
    }

    const data = await response.json();
    console.log('Gemini 2.5 Pro ìŒì„± ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.');

    // í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶”ì¶œ
    const aiResponse = data.candidates?.[0]?.content?.parts?.find(part => part.text)?.text;
    
    // ì˜¤ë””ì˜¤ ì‘ë‹µ ì¶”ì¶œ (API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
    const audioResponse = data.candidates?.[0]?.content?.parts?.find(part => part.inlineData?.mimeType?.startsWith('audio/'));
    
    if (aiResponse) {
      const result = {
        text: aiResponse,
        error: false
      };

      // ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€ (í˜„ì¬ëŠ” Geminiì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ)
      if (audioResponse?.inlineData?.data) {
        result.audioData = audioResponse.inlineData.data;
        result.audioMimeType = audioResponse.inlineData.mimeType;
        
        // ì˜¤ë””ì˜¤ URL ìƒì„± (ì›¹ì—ì„œ ì¬ìƒ ê°€ëŠ¥í•œ í˜•íƒœ)
        const audioBlob = base64ToBlob(audioResponse.inlineData.data, audioResponse.inlineData.mimeType);
        result.audioUrl = URL.createObjectURL(audioBlob);
      } else {
        console.log('Geminiì—ì„œ ì˜¤ë””ì˜¤ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Web TTSë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.');
      }

      return result;
    } else {
      console.error('ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜:', data);
      return {
        text: 'ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
        error: true
      };
    }

  } catch (error) {
    console.error('ìŒì„± ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    return {
      text: `ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`,
      error: true
    };
  }
};

/**
 * Base64 ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
 * @param {string} base64Data - Base64 encoded data
 * @param {string} mimeType - MIME type of the data
 * @returns {Blob} Blob object
 */
const base64ToBlob = (base64Data, mimeType) => {
  const byteCharacters = atob(base64Data);
  const byteNumbers = new Array(byteCharacters.length);
  
  for (let i = 0; i < byteCharacters.length; i++) {
    byteNumbers[i] = byteCharacters.charCodeAt(i);
  }
  
  const byteArray = new Uint8Array(byteNumbers);
  return new Blob([byteArray], { type: mimeType });
};

/**
 * ì›¹ ë¸Œë¼ìš°ì €ì˜ TTS APIë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜ (fallback)
 * @param {string} text - Text to convert to speech
 * @param {string} lang - Language code
 * @returns {Promise<void>} Promise that resolves when speech starts
 */
export const generateWebSpeech = async (text, lang = 'ko-KR') => {
  if (typeof window !== 'undefined' && 'speechSynthesis' in window) {
    // ì´ì „ ìŒì„± ì¤‘ì§€
    window.speechSynthesis.cancel();
    
    return new Promise((resolve, reject) => {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = lang;
      utterance.rate = 0.8; // ì•½ê°„ ë” ì²œì²œíˆ
      utterance.pitch = 1.1; // ì•½ê°„ ë” ë†’ì€ í†¤
      utterance.volume = 1;
      
      // ë” ë‚˜ì€ ìŒì„± í’ˆì§ˆì„ ìœ„í•œ ì„¤ì •
      const voices = window.speechSynthesis.getVoices();
      const koreanVoice = voices.find(voice => 
        voice.lang.includes('ko') || voice.lang.includes('KR')
      );
      
      if (koreanVoice) {
        utterance.voice = koreanVoice;
        console.log('í•œêµ­ì–´ ìŒì„± ì„ íƒë¨:', koreanVoice.name);
      } else {
        console.log('ê¸°ë³¸ ìŒì„± ì‚¬ìš©');
      }
      
      utterance.onstart = () => {
        console.log('ê³ í’ˆì§ˆ TTS ì‹œì‘');
        resolve();
      };
      
      utterance.onerror = (event) => {
        console.error('TTS ì˜¤ë¥˜:', event.error);
        reject(new Error(`TTS ì˜¤ë¥˜: ${event.error}`));
      };
      
      utterance.onend = () => {
        console.log('TTS ì™„ë£Œ');
      };
      
      window.speechSynthesis.speak(utterance);
    });
  } else {
    throw new Error('TTSê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” í™˜ê²½ì…ë‹ˆë‹¤.');
  }
};

/**
 * TTS ì¤‘ì§€
 */
export const stopWebSpeech = () => {
  if (typeof window !== 'undefined' && 'speechSynthesis' in window) {
    window.speechSynthesis.cancel();
  }
};

/**
 * Gemini 2.5 Pro TTSë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ìŒì„± ìƒì„±
 * @param {string} text - ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
 * @param {string} voiceName - ì‚¬ìš©í•  ìŒì„± ì´ë¦„ (ê¸°ë³¸: 'Aoede')
 * @returns {Promise<string|null>} Base64 ì¸ì½”ë”©ëœ PCM ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” ì‹¤íŒ¨ ì‹œ null
 */
export async function generateNativeTTS(text, voiceName = 'Aoede') {
  if (!text) {
    console.error('TTSë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.');
    return null;
  }
  
  console.log(`ğŸ¤ Gemini 2.5 Pro TTS ìš”ì²­ (${voiceName}): "${text}"`);

  const requestBody = {
    contents: [{
      parts: [{ text: `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ, ë§ˆì¹˜ ì¹œêµ¬ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë”°ëœ»í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”. ê°ì •ì„ ë‹´ì•„ì„œ ìƒë™ê° ìˆê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”: ${text}` }]
    }],
    generationConfig: {
      responseModalities: ["AUDIO"],
      speechConfig: {
        voiceConfig: {
          prebuiltVoiceConfig: {
            voiceName: voiceName // AoedeëŠ” ë” ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ìŒì„±
          }
        }
      }
    }
  };

  try {
    const response = await fetch(GEMINI_2_5_TTS_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Gemini 2.5 Pro TTS API ì˜¤ë¥˜:', response.status, errorText);
      
      // 429 ì˜¤ë¥˜ë©´ í• ë‹¹ëŸ‰ ì´ˆê³¼
      if (response.status === 429) {
        console.warn('âš ï¸ Gemini TTS í• ë‹¹ëŸ‰ ì´ˆê³¼, Google Cloud TTSë¡œ fallback');
        return await generateSpeechFromText(text, 'ko-KR-Wavenet-A');
      }
      
      throw new Error(`TTS API ìš”ì²­ ì‹¤íŒ¨: ${response.status}`);
    }

    const data = await response.json();
    
    console.log('ğŸ” Gemini TTS API ì „ì²´ ì‘ë‹µ:', JSON.stringify(data, null, 2));
    
    let audioData = data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    // ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œë„ ì˜¤ë””ì˜¤ ë°ì´í„° ì°¾ê¸°
    if (!audioData) {
      // parts ë°°ì—´ì—ì„œ ì˜¤ë””ì˜¤ ì°¾ê¸°
      const parts = data.candidates?.[0]?.content?.parts || [];
      for (const part of parts) {
        if (part.inlineData && part.inlineData.mimeType && part.inlineData.mimeType.includes('audio')) {
          audioData = part.inlineData.data;
          console.log('ğŸµ ë‹¤ë¥¸ partsì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ë°œê²¬');
          break;
        }
      }
    }

    if (audioData && audioData.length > 0) {
      console.log('âœ… Gemini 2.5 Pro TTS ìŒì„± ìƒì„± ì„±ê³µ', {
        dataLength: audioData.length,
        preview: audioData.substring(0, 50) + '...'
      });
      return audioData; // Base64-encoded PCM audio
    } else {
      console.warn('âš ï¸ Gemini 2.5 Pro TTS ì‘ë‹µì— ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
      console.warn('ğŸ“‹ ì „ì²´ ì‘ë‹µ êµ¬ì¡°:', JSON.stringify(data, null, 2));
      return null;
    }
  } catch (error) {
    console.error('Gemini 2.5 Pro TTS ìŒì„± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    
    // ì˜¤ë¥˜ ë°œìƒ ì‹œ Google Cloud TTSë¡œ fallback
    console.log('ğŸ”„ Google Cloud TTSë¡œ fallback...');
    return await generateSpeechFromText(text, 'ko-KR-Wavenet-A');
  }
}

/**
 * ê¸°ì¡´ Google TTS (fallbackìš©)
 * @param {string} text - ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
 * @param {string} voiceName - ì‚¬ìš©í•  ìŒì„± ì´ë¦„ (ì˜ˆ: 'ko-KR-Standard-A')
 * @returns {Promise<string|null>} Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” ì‹¤íŒ¨ ì‹œ null
 */
export async function generateSpeechFromText(text, voiceName = 'ko-KR-Neural2-A') {
  if (!text) {
    console.error('TTSë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.');
    return null;
  }
  
  console.log(`ğŸ”Š Google Cloud TTS ìš”ì²­ (${voiceName}): "${text}"`);

  // SSMLë¡œ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë°œìŒ
  const ssmlText = `<speak>
    <prosody rate="0.9" pitch="+2st" volume="loud">
      ${text}
    </prosody>
  </speak>`;

  const body = {
    input: {
      ssml: ssmlText, // SSML ì‚¬ìš©ìœ¼ë¡œ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë°œìŒ
    },
    voice: {
      languageCode: 'ko-KR',
      name: voiceName, // Neural2 ë˜ëŠ” Wavenet ìŒì„± ì‚¬ìš©
      ssmlGender: 'FEMALE',
    },
    audioConfig: {
      audioEncoding: 'MP3',
      speakingRate: 0.95, // ì•½ê°„ ëŠë¦¬ê²Œ (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
      pitch: 2.0, // ì•½ê°„ ë†’ì€ í†¤ (ì¹œê·¼í•˜ê²Œ)
      volumeGainDb: 2.0, // ë³¼ë¥¨ ì¡°ê¸ˆ ì¦ê°€
    },
  };

  try {
    const response = await fetch(GOOGLE_TTS_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(body),
    });

    if (!response.ok) {
      const errorData = await response.json();
      console.error('Google Cloud TTS API ì˜¤ë¥˜:', JSON.stringify(errorData, null, 2));
      throw new Error(`Google TTS API ìš”ì²­ ì‹¤íŒ¨: ${response.status}`);
    }

    const data = await response.json();

    if (data.audioContent) {
      console.log('âœ… Google Cloud TTS ìŒì„± ìƒì„± ì„±ê³µ');
      return data.audioContent; // Base64-encoded MP3 audio
    } else {
      console.warn('Google TTS API ì‘ë‹µì— ì˜¤ë””ì˜¤ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.');
      return null;
    }
  } catch (error) {
    console.error('Google Cloud TTS ìŒì„± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
    
    // 403 ì˜¤ë¥˜ë©´ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™” ìƒíƒœ
    if (error.message && error.message.includes('403')) {
      console.warn('âš ï¸ Google Cloud TTS APIê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      console.warn('ğŸ“‹ í™œì„±í™” ë°©ë²•: https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview');
    }
    
    throw error; // ìƒìœ„ì—ì„œ ì²˜ë¦¬
  }
}