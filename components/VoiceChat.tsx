import { useState } from 'react';
import {
  ActivityIndicator,
  Alert,
  StyleSheet,
  Text,
  TouchableOpacity,
  View,
  Platform
} from 'react-native';
import { generateNativeAudio, endConversationSession } from '../backend/hwirang/geminiLiveAudio';
import { validateAIResponse } from '../backend/hwirang/aiSafety';
import RealTimeVoiceInput from './RealTimeVoiceInput';
import AudioPlayer from './AudioPlayer';

interface GoalData {
  goal: string;
  period: string;
  time_slot: string;
  difficulty: string;
  coaching_intensity: 'high' | 'medium' | 'low' | '';
  allDataCollected: boolean;
  confirmationStatus: 'pending' | 'confirmed' | 'denied';
}

interface VoiceChatProps {
  onClose?: () => void;
}

export default function VoiceChat({ onClose }: VoiceChatProps) {
  const [isProcessing, setIsProcessing] = useState(false);
  const [aiResponseText, setAiResponseText] = useState('');
  const [aiAudioData, setAiAudioData] = useState<string | undefined>();
  const [audioMimeType, setAudioMimeType] = useState<string | undefined>();
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTranscription, setCurrentTranscription] = useState('');
  const [conversationHistory, setConversationHistory] = useState<Array<{ type: 'user' | 'ai'; content: string }>>([]);
  const [goalData, setGoalData] = useState<GoalData>({
    goal: '',
    period: '',
    time_slot: '',
    difficulty: '',
    coaching_intensity: '',
    allDataCollected: false,
    confirmationStatus: 'pending',
  });
  
  // Custom hook or useEffect for session management could be even better.
  const handleClose = () => {
    endConversationSession();
    if (onClose) {
      onClose();
    }
  };

  const handleRecordingStop = async (transcription: string) => {
    if (!transcription.trim()) return;
    const newUserMessage = { type: 'user' as const, content: transcription };
    // We pass the full history to the AI processing function
    await processWithAI([...conversationHistory, newUserMessage]);
  };
  
  const processWithAI = async (currentHistory: typeof conversationHistory) => {
    setIsProcessing(true);
    setCurrentTranscription('');
    
    const latestUserMessage = currentHistory[currentHistory.length - 1]?.content || '';
    
    try {
      // ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ë” ìŠ¤ë§ˆíŠ¸í•œ ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜
      const conversationSummary = currentHistory.slice(-6).map(msg => 
        `${msg.type === 'user' ? 'ì‚¬ìš©ì' : 'AI'}: ${msg.content}`
      ).join('\n');
      
      const systemInstruction = `ë‹¹ì‹ ì€ Routy, ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ AI ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ëª©í‘œ ì„¤ì •ì„ ë„ì™€ì£¼ì„¸ìš”.

í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´:
- ëª©í‘œ: ${goalData.goal || 'ë¯¸ì •'}
- ê¸°ê°„: ${goalData.period || 'ë¯¸ì •'}  
- ì‹œê°„ëŒ€: ${goalData.time_slot || 'ë¯¸ì •'}
- ë‚œì´ë„: ${goalData.difficulty || 'ë¯¸ì •'}
- ì½”ì¹­ ê°•ë„: ${goalData.coaching_intensity || 'ë¯¸ì •'}

ìµœê·¼ ëŒ€í™”:
${conversationSummary}

ê·œì¹™:
1. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”
2. ì‘ë‹µì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ 
3. ë¯¸ìˆ˜ì§‘ ì •ë³´ê°€ ìˆìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ìœ¼ë¡œ ìœ ë„
4. ì‚¬ìš©ìì˜ ê°ì •ì„ ê³µê°í•˜ê³  ê²©ë ¤í•´ì£¼ì„¸ìš”
5. ëª¨ë“  ì •ë³´ê°€ ìˆ˜ì§‘ë˜ë©´ ìš”ì•½í•˜ê³  í™•ì¸ ìš”ì²­

ì‚¬ìš©ìì˜ ìµœì‹  ë©”ì‹œì§€ì— ë”°ëœ»í•˜ê²Œ ë°˜ì‘í•˜ê³ , ë‹¤ìŒ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì„¸ìš”.`;

      const { text, audioData, mimeType, error } = await generateNativeAudio(latestUserMessage, systemInstruction);

      if (error) {
        throw new Error(text || 'AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      }
      
      const validation = validateAIResponse(text);
      const finalText = validation.filteredResponse;
      
      // ëª©í‘œ ë°ì´í„° ìë™ ì¶”ì¶œ ì‹œë„
      const updatedGoalData = extractGoalDataFromResponse(finalText, latestUserMessage, goalData);
      setGoalData(updatedGoalData);
      
      setAiResponseText(finalText);
      setAiAudioData(audioData);
      setAudioMimeType(mimeType);

      // ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
      setConversationHistory(prev => [...prev, { type: 'user', content: latestUserMessage }, { type: 'ai', content: finalText }]);

      console.log('âœ… AI ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ:', {
        textLength: finalText.length,
        hasAudioData: !!audioData,
        goalDataComplete: updatedGoalData.allDataCollected
      });

    } catch (error: any) {
      console.error('ğŸš¨ AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
      const errorMessage = 'ì£„ì†¡í•´ìš”, ì²˜ë¦¬ ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?';
      setAiResponseText(errorMessage);
      setAiAudioData(undefined);
      setAudioMimeType(undefined);
      
      // ì˜¤ë¥˜ë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
      setConversationHistory(prev => [...prev, { type: 'user', content: latestUserMessage }, { type: 'ai', content: errorMessage }]);
    } finally {
      setIsProcessing(false);
    }
  };

  // ì‘ë‹µì—ì„œ ëª©í‘œ ë°ì´í„° ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
  const extractGoalDataFromResponse = (aiResponse: string, userMessage: string, currentGoalData: GoalData): GoalData => {
    const updated = { ...currentGoalData };
    
    // ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ëª©í‘œ ì •ë³´ ì¶”ì¶œ
    const userLower = userMessage.toLowerCase();
    const aiLower = aiResponse.toLowerCase();
    
    // ëª©í‘œ ì¶”ì¶œ
    if (!updated.goal && (userLower.includes('ëª©í‘œ') || userLower.includes('í•˜ê³  ì‹¶') || userLower.includes('ê³„íš'))) {
      updated.goal = userMessage;
    }
    
    // ì‹œê°„ëŒ€ ì¶”ì¶œ
    const timeKeywords = ['ì•„ì¹¨', 'ì ì‹¬', 'ì €ë…', 'ë°¤', 'ìƒˆë²½', 'ì˜¤ì „', 'ì˜¤í›„', 'ì‹œ', 'ë¶„'];
    if (!updated.time_slot && timeKeywords.some(keyword => userLower.includes(keyword))) {
      updated.time_slot = userMessage;
    }
    
    // ê¸°ê°„ ì¶”ì¶œ  
    const periodKeywords = ['ì£¼', 'ë‹¬', 'ê°œì›”', 'ë…„', 'ì¼', 'í•˜ë£¨', 'ë§¤ì¼'];
    if (!updated.period && periodKeywords.some(keyword => userLower.includes(keyword))) {
      updated.period = userMessage;
    }
    
    // ë‚œì´ë„ ì¶”ì¶œ
    const difficultyKeywords = ['ì‰¬ìš´', 'ì–´ë ¤ìš´', 'ë³´í†µ', 'í˜ë“ ', 'ê°„ë‹¨í•œ'];
    if (!updated.difficulty && difficultyKeywords.some(keyword => userLower.includes(keyword))) {
      updated.difficulty = userMessage;
    }
    
    // ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ í™•ì¸
    updated.allDataCollected = !!(updated.goal && updated.period && updated.time_slot && updated.difficulty);
    
    return updated;
  };

  return (
    <View style={styles.container}>
      <View style={styles.header}>
        <Text style={styles.title}>AIì™€ ëª©í‘œ ì„¤ì •</Text>
        {onClose && (
          <TouchableOpacity onPress={handleClose} style={styles.closeButton}>
            <Text style={styles.closeButtonText}>âœ•</Text>
          </TouchableOpacity>
        )}
      </View>

      <View style={styles.mainContent}>
        <View style={styles.aiResponseContainer}>
          {isProcessing && !aiResponseText ? (
             <View style={styles.processingContainer}>
               <ActivityIndicator size="large" color="#8A63D2" />
               <Text style={styles.processingText}>Routyê°€ ìƒê° ì¤‘ì´ì—ìš”...</Text>
             </View>
          ) : (
            <>
              <Text style={styles.aiResponseText}>
                {aiResponseText || "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë‹¹ì‹ ì˜ ëª©í‘œ ë‹¬ì„±ì„ ë„ì™€ì¤„ AI ì½”ì¹˜, Routyì˜ˆìš”. ğŸ’ª ì–´ë–¤ ìƒˆë¡œìš´ ëª©í‘œë¥¼ ì„¸ì›Œë³¼ê¹Œìš”?"}
              </Text>
              
              <AudioPlayer
                audioData={aiAudioData}
                audioMimeType={audioMimeType}
                text={aiResponseText || "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë‹¹ì‹ ì˜ ëª©í‘œ ë‹¬ì„±ì„ ë„ì™€ì¤„ AI ì½”ì¹˜, Routyì˜ˆìš”. ì–´ë–¤ ìƒˆë¡œìš´ ëª©í‘œë¥¼ ì„¸ì›Œë³¼ê¹Œìš”?"} 
                onPlaybackStatusChange={setIsPlaying}
                autoPlay={true}
                showControls={false}
              />
            </>
          )}
        </View>

        <View style={styles.userInputContainer}>
          <Text style={styles.userInputLabel}>ë‚˜ì˜ ë‹µë³€</Text>
          <View style={styles.transcriptionDisplay}>
            <Text style={styles.transcriptionText}>{currentTranscription || '...'}</Text>
          </View>
          <RealTimeVoiceInput
            onTranscriptionUpdate={setCurrentTranscription}
            onRecordingStop={handleRecordingStop}
            isEnabled={!isProcessing}
          />
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#1c1c2e',
    paddingHorizontal: 16,
    paddingBottom: 24,
    paddingTop: Platform.OS === 'android' ? 40 : 50,
  },
  header: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    marginBottom: 16,
  },
  title: { fontSize: 24, fontWeight: 'bold', color: '#ffffff' },
  closeButton: {
    width: 32, height: 32, borderRadius: 16,
    backgroundColor: '#3a3a50',
    justifyContent: 'center', alignItems: 'center',
  },
  closeButtonText: { fontSize: 18, color: '#ffffff' },
  mainContent: { flex: 1, justifyContent: 'space-between' },
  aiResponseContainer: {
    flex: 2, // Less space
    justifyContent: 'center', alignItems: 'center',
    padding: 20, borderRadius: 20,
    backgroundColor: '#2a2a3e', marginBottom: 24,
  },
  aiResponseText: {
    fontSize: 20, fontWeight: '600',
    color: '#e0e0ff', textAlign: 'center', lineHeight: 30,
  },
  processingContainer: { justifyContent: 'center', alignItems: 'center' },
  processingText: { marginTop: 16, fontSize: 16, color: '#a9a9c2' },
  userInputContainer: {
    flex: 3, // More space
  },
  userInputLabel: {
    fontSize: 16, fontWeight: '600',
    color: '#a9a9c2', marginBottom: 8, textAlign: 'center',
  },
  transcriptionDisplay: {
    flex: 1,
    backgroundColor: '#1c1c2e', borderRadius: 12,
    padding: 16, justifyContent: 'center',
    marginBottom: 16, borderWidth: 1, borderColor: '#3a3a50',
    minHeight: 60,
  },
  transcriptionText: {
    fontSize: 18, color: '#e0e0ff',
    fontStyle: 'italic', textAlign: 'center',
  },
  progressIndicator: {
    marginTop: 12,
    paddingHorizontal: 16,
    paddingVertical: 8,
    backgroundColor: '#3a3a50',
    borderRadius: 20,
  },
  progressText: {
    fontSize: 14,
    color: '#a9a9c2',
    textAlign: 'center',
    fontWeight: '500',
  },
  debugInfo: {
    marginTop: 8,
    paddingHorizontal: 12,
    paddingVertical: 6,
    backgroundColor: 'rgba(255, 255, 255, 0.1)',
    borderRadius: 8,
  },
  debugText: {
    fontSize: 12,
    color: '#8a8a8a',
    textAlign: 'center',
  },
});
