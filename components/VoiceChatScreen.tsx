import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  View,
  StyleSheet,
  Modal,
  Text,
  TouchableOpacity,
  StatusBar,
  SafeAreaView,
  Platform,
  AppState,
} from 'react-native';
import { MaterialIcons } from '@expo/vector-icons';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
  withTiming,
  withSpring,
  Easing,
} from 'react-native-reanimated';
import * as Haptics from 'expo-haptics';
import { Audio, InterruptionModeAndroid } from 'expo-av';
import * as FileSystem from 'expo-file-system';

import VoiceVisualizer from './VoiceVisualizer';
import VoiceChatControls from './VoiceChatControls';
import { VoiceChatState, VOICE_STATE_CONFIG } from '../types/voice';
import { useHabitStore } from '../lib/habitStore';
import { Colors } from '../constants/Colors';
import { Spacing } from '../constants/Spacing';
import { useColorScheme } from '../hooks/useColorScheme';
import { koreanTextStyle } from '../utils/koreanUtils';
import { useIsDebugMode } from '../src/config/debug';
// import { processVoiceWithPolling } from '../services/supabaseVoiceService'; // ê¸°ì¡´ í´ë§ ë°©ì‹ ì œê±°

// Supabase í´ë¼ì´ì–¸íŠ¸ import ì¶”ê°€
import { supabase } from '../backend/supabase/client';

// --- Props and other interfaces remain the same ---
export interface VoiceChatScreenProps {
  visible: boolean;
  mode: 'goalSetting' | 'home' | 'report';
  onClose: () => void;
  onComplete: (data: any) => void;
  onError?: (error: string) => void;
  onSwitchToText?: () => void;
  enableStepProgression?: boolean;
  isNewGoal?: boolean; // ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€ ì—¬ë¶€
}

interface GoalSettingStepData {
  habitName?: string;
  goalPeriod?: string;
  availableTime?: string;
  difficultyReason?: string;
  restrictedApps?: string;
  persona?: 'Easy' | 'Medium' | 'Hard';
}

const STEP_TITLES: Record<number, string> = {
    1: 'ë‹¹ì‹ ì´ ì´ë£¨ê³  ì‹¶ì€ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?',
    2: 'ëª©í‘œë¥¼ ì–¸ì œê¹Œì§€ ë‹¬ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?',
    3: 'ì–¸ì œ ì‹œê°„ì„ ë‚´ì„œ ì‹¤ì²œí•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?',
    4: 'ì´ ìŠµê´€ì„ í˜•ì„±í•˜ëŠ” ë° ì–´ë ¤ìš´ ì ì´ ìˆë‚˜ìš”?',
    5: 'ì–´ë–¤ ì•±ì„ ì œí•œí•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?',
    6: 'ì–´ë–¤ ì½”ì¹­ ìŠ¤íƒ€ì¼ì„ ì›í•˜ì‹œë‚˜ìš”?'
};

const getSystemInstructionForMode = (mode: VoiceChatScreenProps['mode'], currentStep?: number): string => {
    // This function seems complex but correct, so we'll keep it as is.
    const basePrompt = `You are 'ë£¨í‹°' (Routy), a friendly Korean habit coach.\n\nRULES: Korean only, ALWAYS speak numbers in Korean (ì‚¼ê°œì›”, ë°±ë§Œì›, ì—¬ì„¯ì‹œ, ì¼ê³±ì‹œ, ì—¬ëŸì‹œ), NEVER use English numbers, summarize as "~~ê°€ ëª©í‘œì‹œêµ°ìš”", one question at a time, handle interruptions, 2-3 sentences max.\n\nCRITICAL: When speaking, use Korean numbers: ì‚¼ê°œì›”, ë°±ë§Œì›, ì—¬ì„¯ì‹œ, ì¼ê³±ì‹œ, ì—¬ëŸì‹œ, ì•„í™‰ì‹œ, ì—´ì‹œ, ì—´í•œì‹œ, ì—´ë‘ì‹œ\n\nEMOTION: ALWAYS use "ì™€!", "ì˜¤!", "í™”ì´íŒ…!", "ìŒ...", "ì•„..." and "!", "?"\n\nCRITICAL: NEVER create routines, plans, or projects. Your ONLY job is to collect information.`;
    // ... (rest of the function is omitted for brevity but should be kept)
    return basePrompt;
};

const VoiceChatScreen: React.FC<VoiceChatScreenProps> = ({
  visible,
  mode,
  onClose,
  onComplete,
  onError,
  onSwitchToText,
  enableStepProgression = true,
  isNewGoal = false, // ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€ ì—¬ë¶€
}) => {
  const [currentState, setCurrentState] = useState<VoiceChatState>('idle');
  const [isPaused, setIsPaused] = useState(false);
  const [displayedText, setDisplayedText] = useState('');
  const [aiResponseText, setAiResponseText] = useState(''); // AI ì‘ë‹µ í…ìŠ¤íŠ¸ ë³„ë„ ì €ì¥
  const [audioQueue, setAudioQueue] = useState<string[]>([]);
  const [isPlayingAudio, setIsPlayingAudio] = useState(false);
  
  // --- Recording & Playback State ---
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const [sound, setSound] = useState<Audio.Sound | null>(null);
  
  const fullResponseTextRef = useRef('');
  const colorScheme = useColorScheme();
  const colors = Colors[colorScheme];
  const { addMessageToHistory, conversationHistory } = useHabitStore();

  // --- Debug Mode State ---
  const isDebugMode = useIsDebugMode();

  // --- Goal Setting State ---
  const [currentStep, setCurrentStep] = useState(1);
  const [progressValue, setProgressValue] = useState(0);
  const shouldEnableStepProgression = mode === 'goalSetting' && enableStepProgression;

  // --- Session Management for Context Persistence ---
  const [sessionId, setSessionId] = useState<string | null>(null);
  const [sessionStartTime, setSessionStartTime] = useState<Date | null>(null);
  const [conversationMemory, setConversationMemory] = useState<string>(''); // ëŒ€í™” ê¸°ì–µ ì¶”ê°€

  // --- Animations ---
  const fadeAnim = useSharedValue(0);
  const scaleAnim = useSharedValue(0.8);
  const textFadeAnim = useSharedValue(0);
  
  // Animation values for UI components
  const visualizerFadeAnim = useSharedValue(1);
  const buttonsFadeAnim = useSharedValue(1);

  // ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜
  const initializeSession = useCallback(() => {
    const newSessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    setSessionId(newSessionId);
    setSessionStartTime(new Date());
    
    // ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€ì¸ ê²½ìš° ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    if (isNewGoal) {
      useHabitStore.getState().clearConversationHistory();
      setConversationMemory('');
      console.log('[ìŒì„±ì±„íŒ…] ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€ ëª¨ë“œ - ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”');
    } else {
      // ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ìœ ì§€
      const store = useHabitStore.getState();
      const history = store.conversationHistory;
      if (history.length > 0) {
        const recentMessages = history.slice(-10).map(msg => `${msg.role}: ${msg.text}`).join('\n');
        setConversationMemory(recentMessages);
        console.log('[ìŒì„±ì±„íŒ…] ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ë¡œë“œ:', recentMessages.length, 'ì');
      } else {
        console.log('[ìŒì„±ì±„íŒ…] ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì—†ìŒ');
      }
    }
    
    console.log('[ìŒì„±ì±„íŒ…] ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘:', newSessionId, 'ìƒˆë¡œìš´ ëª©í‘œ:', isNewGoal);
  }, [isNewGoal]);

  // ì„¸ì…˜ ì •ë¦¬ í•¨ìˆ˜
  const cleanupSession = useCallback(() => {
    setSessionId(null);
    setSessionStartTime(null);
    // ëŒ€í™” ê¸°ë¡ë„ ì •ë¦¬ (ìƒˆë¡œìš´ ì„¸ì…˜ì„ ìœ„í•´)
    useHabitStore.getState().clearConversationHistory();
    console.log('[ìŒì„±ì±„íŒ…] ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ');
  }, []);

  // ì»´í¬ë„ŒíŠ¸ê°€ ë§ˆìš´íŠ¸ë˜ê±°ë‚˜ modeê°€ ë³€ê²½ë  ë•Œ ì„¸ì…˜ ì´ˆê¸°í™”
  useEffect(() => {
    if (visible && mode) {
      // ì´ì „ ì„¸ì…˜ ì •ë¦¬ í›„ ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘
      cleanupSession();
      
      const subscription = AppState.addEventListener('change', (nextAppState) => {
        if (nextAppState.match(/inactive|background/) && visible) {
          // AppState ë³€ê²½ ì‹œì—ë„ ì„¸ì…˜ ìœ ì§€ (ëŒ€í™”ê°€ ëë‚  ë•Œê¹Œì§€)
          // endSession().then(() => onClose());
          onClose();
        }
      });
      return () => subscription.remove();
    }
  }, [visible, mode, onClose]);

  useEffect(() => {
    if (visible) {
      fadeAnim.value = withTiming(1, { duration: 300 });
      scaleAnim.value = withSpring(1, { damping: 15, stiffness: 300 });
      textFadeAnim.value = withTiming(1, { duration: 500, easing: Easing.out(Easing.quad) });
      
      
      startSession();
    } else {
      fadeAnim.value = withTiming(0, { duration: 200 });
      scaleAnim.value = withTiming(0.8, { duration: 200 });
      textFadeAnim.value = withTiming(0, { duration: 200 });
      
      
      // ì„¸ì…˜ì„ ì¦‰ì‹œ ì¢…ë£Œí•˜ì§€ ì•Šê³  ìœ ì§€ (ëŒ€í™”ê°€ ëë‚  ë•Œê¹Œì§€)
      // endSession();
    }
  }, [visible]);

  const audioChunksRef = useRef<Blob[]>([]);

  const startRecording = async () => {
    if (recordingRef.current) await stopRecording();
    setLiveTranscript(''); // ì´ì „ ê¸°ë¡ ì´ˆê¸°í™”
    try {
        if (Platform.OS === 'web') {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            userMediaStream.current = stream;
            
            audioChunksRef.current = [];
            const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
            recordingRef.current = recorder;

            recorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    audioChunksRef.current.push(event.data);
                }
            };
            recorder.start(250);
        } else {
            await Audio.requestPermissionsAsync();
            const { recording } = await Audio.Recording.createAsync(Audio.RecordingOptionsPresets.HIGH_QUALITY);
            recordingRef.current = recording;
            await recordingRef.current.startAsync();
        }
        setCurrentState('listening');
    } catch (err) {
      console.error('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨', err);
      setCurrentState('error');
    }
  };

  const resampleBuffer = (audioBuffer: AudioBuffer, targetSampleRate: number): Int16Array => {
    const sourceSampleRate = audioBuffer.sampleRate;
    const sourceData = audioBuffer.getChannelData(0);
    if (sourceSampleRate === targetSampleRate) {
        const pcmData = new Int16Array(sourceData.length);
        for (let i = 0; i < sourceData.length; i++) {
            let val = Math.max(-1, Math.min(1, sourceData[i]));
            pcmData[i] = val < 0 ? val * 0x8000 : val * 0x7FFF;
        }
        return pcmData;
    }

    const sourceLength = sourceData.length;
    const targetLength = Math.round(sourceLength * (targetSampleRate / sourceSampleRate));
    const resampledData = new Int16Array(targetLength);
    
    for (let i = 0; i < targetLength; i++) {
        const srcIndex = (i / targetLength) * sourceLength;
        const srcIndexFloor = Math.floor(srcIndex);
        const srcIndexCeil = Math.ceil(srcIndex);
        const weight = srcIndex - srcIndexFloor;

        const sample1 = sourceData[srcIndexFloor] || 0;
        const sample2 = sourceData[srcIndexCeil] || 0;
        
        const interpolatedSample = sample1 + (sample2 - sample1) * weight;
        
        let pcmSample = Math.max(-1, Math.min(1, interpolatedSample));
        pcmSample = pcmSample < 0 ? pcmSample * 0x8000 : pcmSample * 0x7FFF;
        resampledData[i] = pcmSample;
    }
    return resampledData;
  }

  const stopRecordingAndSend = async () => {
    if (!recordingRef.current) return;
    
    setCurrentState('processing');
    
    try {
      let base64Audio = '';
      let mimeType = 'audio/pcm;rate=16000';

      if (Platform.OS === 'web') {
        if (recordingRef.current.state === 'recording') {
          recordingRef.current.stop();
        }
        if (audioChunksRef.current.length === 0) {
          console.warn('[ìŒì„±ì±„íŒ…] ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
          setCurrentState('idle');
          return;
        }
        
        // ë„ˆë¬´ ì§§ì€ ìŒì„± ì²´í¬ (ìµœì†Œ 0.5ì´ˆ)
        const totalDuration = audioChunksRef.current.length * 0.25; // 250ms chunks
        if (totalDuration < 0.5) {
          console.warn('[ìŒì„±ì±„íŒ…] ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš”.');
          setCurrentState('idle');
          return;
        }
        
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        const arrayBuffer = await audioBlob.arrayBuffer();
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        const pcmData = resampleBuffer(audioBuffer, 16000);
        
        let binary = '';
        const bytes = new Uint8Array(pcmData.buffer);
        const len = bytes.byteLength;
        const chunkSize = 8192;
        for (let i = 0; i < len; i += chunkSize) {
          const chunk = bytes.subarray(i, i + chunkSize);
          binary += String.fromCharCode.apply(null, chunk as unknown as number[]);
        }
        base64Audio = btoa(binary);

      } else {
        const recording = recordingRef.current;
        await recording.stopAndUnloadAsync();
        const uri = recording.getURI();
        if (!uri) throw new Error('ë…¹ìŒ URIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        
        // ëª¨ë°”ì¼ì—ì„œë„ ìµœì†Œ ë…¹ìŒ ì‹œê°„ ì²´í¬
        const recordingDuration = recording.getStatusAsync ? await recording.getStatusAsync() : null;
        if (recordingDuration && recordingDuration.durationMillis < 500) {
          console.warn('[ìŒì„±ì±„íŒ…] ìŒì„±ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ì£¼ì„¸ìš”.');
          setCurrentState('idle');
          return;
        }
        
        base64Audio = await FileSystem.readAsStringAsync(uri, { encoding: FileSystem.EncodingType.Base64 });
      }
      
      recordingRef.current = null;

      if (sessionRef.current && base64Audio) {
        await sessionRef.current.sendAudio(base64Audio, mimeType);
        
        const response = await sessionRef.current.waitForResponse();
        
        // ì‘ë‹µ ë””ë²„ê¹… ë¡œê·¸
        console.log('[ìŒì„±ì±„íŒ…] AI ì‘ë‹µ ë°›ìŒ:', {
          hasResponse: !!response,
          hasText: !!response?.text,
          hasUserInput: !!response?.userInput,
          userInput: response?.userInput,
          text: response?.text,
          textLength: response?.text?.length
        });
        
        // ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬
        if (!response || !response.text || response.text.trim().length === 0) {
          console.warn('[ìŒì„±ì±„íŒ…] AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
          setCurrentState('idle');
          return;
        }
        
        // ë„ˆë¬´ ì§§ì€ ì‘ë‹µ ì²´í¬ (ìµœì†Œ 3ê¸€ì)
        if (response.text.trim().length < 3) {
          console.warn('[ìŒì„±ì±„íŒ…] AI ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
          setCurrentState('idle');
          return;
        }
        
        // Add messages to the global store
        if ((response as any).userInput && (response as any).userInput.trim().length > 0) {
          addMessageToHistory({ role: 'user', text: (response as any).userInput });
        } else {
          // userInputì´ ë¹„ì–´ìˆìœ¼ë©´ ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©ì„ ì¶”ì •í•˜ì—¬ ì¶”ê°€
          console.log('[ìŒì„±ì±„íŒ…] userInputì´ ë¹„ì–´ìˆìŒ, ì‚¬ìš©ì ì…ë ¥ ì¶”ì •');
          addMessageToHistory({ role: 'user', text: 'ì‚¬ìš©ì ìŒì„± ì…ë ¥' });
        }
        
        // AI ì‘ë‹µì—ì„œ êµ¬ì¡°í™”ëœ ë¶€ë¶„ ì œê±°í•˜ê³  ì‚¬ìš©ìì—ê²ŒëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë§Œ ë³´ì—¬ì£¼ê¸°
        let displayText = response.text;
        if (response.text.includes('ëª©í‘œ:') && response.text.includes('ê¸°ê°„:') && response.text.includes('ì‹œê°„:')) {
          // êµ¬ì¡°í™”ëœ ë¶€ë¶„ì„ ì œê±°í•˜ê³  ìì—°ì–´ ë¶€ë¶„ë§Œ ë‚¨ê¸°ê¸°
          const naturalPart = response.text.split('ëª©í‘œ:')[0].trim();
          if (naturalPart) {
            displayText = naturalPart;
            console.log('[ìŒì„±ì±„íŒ…] êµ¬ì¡°í™”ëœ ë¶€ë¶„ ì œê±°ë¨, ìì—°ì–´ ë¶€ë¶„ë§Œ í‘œì‹œ:', displayText);
          }
        }
        
        // Start typewriter animation instead of immediately adding to history
        console.log('[ìŒì„±ì±„íŒ…] íƒ€ì´í”„ë¼ì´í„° ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘:', displayText);
        startTypewriterAnimation(displayText);

        // ì‹¤ì‹œê°„ ë‹¨ê³„ ê°ì§€ (ëª¨ë“  AI ì‘ë‹µì—ì„œ ì‹¤í–‰)
        processResponseForStepDetection(response.text);

        // ì¤‘ê°„ ì‘ë‹µì—ì„œëŠ” ì •ë³´ ì¶”ì¶œí•˜ì§€ ì•ŠìŒ - ìµœì¢… ì •ë¦¬ ë‹¨ê³„ì—ì„œë§Œ ì¶”ì¶œ
        if (response.text.includes('ì •ë¦¬í•´ë³¼ê²Œìš”') || response.text.includes('ë§ë‚˜ìš”?')) {
          console.log('[ìŒì„±ì±„íŒ…] ìµœì¢… ì •ë¦¬ ë‹¨ê³„ ê°ì§€ - ì •ë³´ ì¶”ì¶œ ì§„í–‰');
          const updatedGoalData = extractFinalGoalInfo(response.text);
          console.log('[ìŒì„±ì±„íŒ…] ìµœì¢… ëª©í‘œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ:', updatedGoalData);
        } else {
          console.log('[ìŒì„±ì±„íŒ…] ì¤‘ê°„ ì‘ë‹µ - ì •ë³´ ì¶”ì¶œ ê±´ë„ˆëœ€');
        }

        // ë©”ì‹œì§€ ì¹´ìš´í„° ì¦ê°€
        // messageCountRef.current += 1; // ì´ ë¶€ë¶„ì€ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬

        // 3ë²ˆì§¸ ì‘ë‹µ í›„ ì„±ëŠ¥ ìµœì í™” (ëŒ€í™” ë§¥ë½ ìœ ì§€)
        // if (messageCountRef.current >= 3) { // ì´ ë¶€ë¶„ì€ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
        //   console.log('[ìŒì„±ì±„íŒ…] 3ë²ˆì§¸ ì‘ë‹µ ì™„ë£Œ, ì„±ëŠ¥ ìµœì í™” ì‹œì‘');
        //   setTimeout(() => {
        //     optimizePerformance();
        //   }, 1000); // 1ì´ˆ í›„ ìµœì í™”
        // }

        setLiveTranscript('');

        // AI ìŒì„± ì‘ë‹µ ì¬ìƒ
        if (response.audioData) {
          console.log('[ìŒì„±ì±„íŒ…] AI ìŒì„± ì‘ë‹µ ì¬ìƒ ì‹œì‘ (íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ê³¼ ë™ì‹œ)');
          await playAudio(response.audioData, response.mimeType, response.text);
        } else {
          console.log('[ìŒì„±ì±„íŒ…] AI ìŒì„± ì‘ë‹µ ë°ì´í„° ì—†ìŒ, íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ë§Œ í‘œì‹œ');
          // ìŒì„±ì´ ì—†ì–´ë„ ëŒ€í™” ì™„ë£Œ ê°ì§€
          if (mode === 'goalSetting' && isConversationComplete(response.text)) {
            console.log('[ìŒì„±ì±„íŒ…] AI ìŒì„± ì—†ìŒ, ëŒ€í™” ì™„ë£Œ ê°ì§€ë¨! ê³¨ ìŠ¤í… 5ë¡œ ì´ë™í•©ë‹ˆë‹¤.');
            await handleConversationComplete();
          }
          setCurrentState('idle');
        }

        // ëŒ€í™” ì™„ë£Œ ê°ì§€ëŠ” ìŒì„± ì¬ìƒì´ ëë‚œ í›„ì—ë§Œ ì‹¤í–‰
        // playAudio í•¨ìˆ˜ì—ì„œ ì¬ìƒ ì™„ë£Œ ì‹œ ì½œë°±ìœ¼ë¡œ ì²˜ë¦¬
      } else {
        setCurrentState('idle');
      }
    } catch (error) {
      console.error('[ìŒì„±ì±„íŒ…] ë°œí™” ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      setCurrentState('error');
      
      // ì—ëŸ¬ ë°œìƒ ì‹œ ìƒíƒœ ë³µêµ¬
      setTimeout(() => {
        initializeSession();
      }, 100);
    }
    return () => {
      if (!visible) {
        cleanupSession();
      }
    };
  }, [visible, mode, initializeSession, cleanupSession]);

  // --- ìƒˆë¡œìš´ ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬ í•¨ìˆ˜ ---
  const processVoiceWithNewAsyncMethod = useCallback(async (base64Audio: string) => {
    try {
      console.log('[ìŒì„±ì±„íŒ…] ìƒˆë¡œìš´ ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ìŒì„± ì²˜ë¦¬ ì‹œì‘...');
      console.log('[ìŒì„±ì±„íŒ…] ì˜¤ë””ì˜¤ ë°ì´í„° ê¸¸ì´:', base64Audio.length);
      console.log('[ìŒì„±ì±„íŒ…] í˜„ì¬ ëŒ€í™” ê¸°ì–µ:', conversationMemory.length, 'ì');
      console.log('[ìŒì„±ì±„íŒ…] ìƒˆë¡œìš´ ëª©í‘œ ëª¨ë“œ:', isNewGoal);
      
      // Supabase í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
      const { data: { user }, error: authError } = await supabase.auth.getUser();
      console.log('[ìŒì„±ì±„íŒ…] ì¸ì¦ ìƒíƒœ:', { 
        user: user?.id ? 'ì¸ì¦ë¨' : 'ì¸ì¦ ì•ˆë¨', 
        userId: user?.id,
        authError: authError?.message 
      });
      
      // 1. í•¨ìˆ˜ í˜¸ì¶œ (ë¹ ë¥¸ ì‘ë‹µ)
      console.log('[ìŒì„±ì±„íŒ…] ai-voice-chat í•¨ìˆ˜ í˜¸ì¶œ ì‹œì‘...');
      // ì‚¬ìš©ì ëª©í‘œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
      let userGoals = null;
      try {
        const { data: goals, error: goalsError } = await supabase
          .from('habits')
          .select('*')
          .eq('user_id', user?.id);
        
        if (goalsError) {
          console.error('[ìŒì„±ì±„íŒ…] ëª©í‘œ ì¡°íšŒ ì˜¤ë¥˜:', goalsError);
        } else {
          userGoals = goals;
          console.log('[ìŒì„±ì±„íŒ…] ì‚¬ìš©ì ëª©í‘œ ì¡°íšŒ ì™„ë£Œ:', userGoals?.length || 0, 'ê°œ');
        }
      } catch (error) {
        console.error('[ìŒì„±ì±„íŒ…] ëª©í‘œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:', error);
      }
      
      // í™”ë©´ë³„ ë§¥ë½ ì •ë³´ ì „ë‹¬ (ëª©í‘œ ì •ë³´ í¬í•¨)
      const context = {
        screen: mode === 'home' ? 'home' : mode, // 'goalSetting', 'home', 'report'
        currentStep: mode === 'goalSetting' ? currentStep : (shouldEnableStepProgression ? currentStep : undefined),
        hasGoal: mode === 'home', // home í™”ë©´ì—ì„œëŠ” ëª©í‘œê°€ ìˆë‹¤ê³  ê°€ì •
        isDebugMode: isDebugMode, // ë””ë²„ê·¸ ëª¨ë“œ ìƒíƒœ ì¶”ê°€
        userGoals: (mode === 'goalSetting' || isNewGoal) ? [] : userGoals, // ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€ ëª¨ë“œì¼ ë•ŒëŠ” ê¸°ì¡´ ëª©í‘œ ì •ë³´ ì™„ì „ ë¬´ì‹œ
        sessionId: sessionId, // ì„¸ì…˜ ID ì¶”ê°€
        sessionStartTime: sessionStartTime, // ì„¸ì…˜ ì‹œì‘ ì‹œê°„ ì¶”ê°€
        isNewGoal: isNewGoal, // ìƒˆë¡œìš´ ëª©í‘œ ì¶”ê°€ ì—¬ë¶€
        conversationMemory: conversationMemory // ëŒ€í™” ê¸°ì–µ ì¶”ê°€
      };

      console.log('[ìŒì„±ì±„íŒ…] ì „ì†¡í•  ì»¨í…ìŠ¤íŠ¸:', {
        screen: context.screen,
        currentStep: context.currentStep,
        isNewGoal: context.isNewGoal,
        userGoalsLength: context.userGoals?.length || 0,
        conversationMemoryLength: context.conversationMemory?.length || 0
      });

      const { data, error } = await supabase.functions.invoke('ai-voice-chat', {
        body: { 
          audio: base64Audio,
          context: context
        },
      });

      if (error) {
        console.error('[ìŒì„±ì±„íŒ…] í•¨ìˆ˜ í˜¸ì¶œ ì‹¤íŒ¨:', error);
        console.error('[ìŒì„±ì±„íŒ…] ì—ëŸ¬ ìƒì„¸ ì •ë³´:', {
          name: error.name,
          message: error.message,
          status: error.status,
          details: error.details
        });
        throw new Error(`ìŒì„± ì²˜ë¦¬ ì‹¤íŒ¨: ${error.message}`);
      }

      // 2. í•¨ìˆ˜ë¡œë¶€í„° 'ì§„ë™ë²¨(jobId)'ê³¼ í…ìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì¦‰ì‹œ ë°›ìŒ
      const { jobId, userText, responseText, goalSettingComplete, nextScreen, collectedGoalInfo } = data;
      console.log('[ìŒì„±ì±„íŒ…] ì‘ì—… ID ë°›ìŒ:', jobId);
      
      // ëª©í‘œ ì„¤ì • ì™„ë£Œ ì²´í¬
      if (goalSettingComplete && mode === 'goalSetting') {
        console.log('[ìŒì„±ì±„íŒ…] ğŸ¯ ëª©í‘œ ì„¤ì • ì™„ë£Œë¨! onComplete ì½œë°± í˜¸ì¶œ');
        console.log('[ìŒì„±ì±„íŒ…] ğŸ¯ ì™„ë£Œ ë°ì´í„°:', {
          goalSettingComplete,
          nextScreen,
          collectedGoalInfo,
          userText,
          responseText
        });
        
        // ì¦‰ì‹œ onComplete ì½œë°± í˜¸ì¶œ
        if (onComplete) {
          onComplete({
            goalSettingComplete: true,
            nextScreen: nextScreen || 'goalSettingStep5',
            collectedGoalInfo: collectedGoalInfo || {},
            userText: userText,
            responseText: responseText
          });
        }
        
        // ìƒíƒœ ì´ˆê¸°í™”
        setCurrentState('idle');
        setDisplayedText('');
        setAiResponseText('');
        return; // ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•ŠìŒ
      }
      
      // 3. ì‚¬ìš©ì í…ìŠ¤íŠ¸ì™€ AI ì‘ë‹µì„ ì¦‰ì‹œ UIì— í‘œì‹œ
      addMessageToHistory({ role: 'user', text: userText });
      setAiResponseText(responseText); // AI ì‘ë‹µ í…ìŠ¤íŠ¸ ì €ì¥ (í™”ë©´ì—ëŠ” ì•„ì§ í‘œì‹œ ì•ˆí•¨)
      fullResponseTextRef.current = responseText;
      
      // ëŒ€í™” ê¸°ì–µ ì—…ë°ì´íŠ¸ (ìƒˆë¡œìš´ ì •ë³´ ì¶”ê°€)
      const newMemory = `${conversationMemory}\nì‚¬ìš©ì: ${userText}\nAI: ${responseText}`.trim();
      setConversationMemory(newMemory);
      console.log('[ìŒì„±ì±„íŒ…] ëŒ€í™” ê¸°ì–µ ì—…ë°ì´íŠ¸:', newMemory.length, 'ì');
      
      // í™”ë©´ì—ëŠ” "ìƒê°ì¤‘ì´ì—ìš”" ìƒíƒœ ìœ ì§€
      
      // 4. ì¦‰ì‹œ ai-voice-finish í•¨ìˆ˜ í˜¸ì¶œ (íŠ¸ë¦¬ê±° ëŒ€ì‹ )
      console.log('[ìŒì„±ì±„íŒ…] ai-voice-finish í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ ì‹œì‘...');
      try {
        const finishResult = await supabase.functions.invoke('ai-voice-finish', {
          body: { 
            record: {
              job_id: jobId,
              response_text: responseText
            },
            context: {
              isDebugMode: isDebugMode
            }
          }
        });
        
        if (finishResult.error) {
          console.error('[ìŒì„±ì±„íŒ…] ai-voice-finish í˜¸ì¶œ ì‹¤íŒ¨:', finishResult.error);
          throw new Error(`ìŒì„± ìƒì„± ì‹¤íŒ¨: ${finishResult.error.message}`);
        }
        
        console.log('[ìŒì„±ì±„íŒ…] ai-voice-finish í˜¸ì¶œ ì„±ê³µ:', finishResult.data);
        
        // 5. ë””ë²„ê·¸ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
        if (isDebugMode) {
          // ë””ë²„ê·¸ ëª¨ë“œ: DB í´ë§ ê±´ë„ˆë›°ê¸°, ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¡œ ìŒì„± ì¬ìƒ
          console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - DB í´ë§ ê±´ë„ˆë›°ê¸°, ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¡œ ìŒì„± ì¬ìƒ');
          
          // ai-voice-finish ì‘ë‹µì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° í™•ì¸
          console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ì‘ë‹µ ë°ì´í„° ìƒì„¸ ë¶„ì„:', {
            hasData: !!finishResult.data,
            hasAudioData: !!finishResult.data?.audioData,
            audioDataLength: finishResult.data?.audioData?.length || 0,
            mimeType: finishResult.data?.mimeType,
            isDebugMode: finishResult.data?.isDebugMode,
            rawDataType: typeof finishResult.data, // ë°ì´í„° íƒ€ì… í™•ì¸
            // Base64 ë°ì´í„°ëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ ë¡œê·¸ì—ì„œ ì œê±°
          });

          // ì‘ë‹µ ë°ì´í„°ê°€ ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹± ì‹œë„
          let parsedData = finishResult.data;
          if (typeof finishResult.data === 'string') {
            try {
              parsedData = JSON.parse(finishResult.data);
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ë¬¸ìì—´ íŒŒì‹± ì™„ë£Œ:', parsedData);
            } catch (parseError) {
              console.error('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ë¬¸ìì—´ íŒŒì‹± ì‹¤íŒ¨:', parseError);
            }
          }

          // audioDataê°€ ì§ì ‘ ìˆê±°ë‚˜ data ì†ì„± ì•ˆì— ìˆì„ ìˆ˜ ìˆìŒ
          const audioData = parsedData?.audioData || parsedData?.data?.audioData;
          const mimeType = parsedData?.mimeType || parsedData?.data?.mimeType;

          if (audioData) {
            console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ì˜¤ë””ì˜¤ ë°ì´í„° ë°›ìŒ, ìŒì„± ì¬ìƒ ì‹œì‘');

            try {
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - Base64 ë””ì½”ë”© ì‹œì‘');

              // Base64 ë¬¸ìì—´ íŒ¨ë”© í™•ì¸ ë° ìˆ˜ì •
              let paddedAudioData = audioData;
              while (paddedAudioData.length % 4 !== 0) {
                paddedAudioData += '=';
              }
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - Base64 íŒ¨ë”© ì™„ë£Œ, ê¸¸ì´:', paddedAudioData.length);

              // Base64 ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Uint8Arrayë¡œ ë³€í™˜
              const decodedData = atob(paddedAudioData);
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - Base64 ë””ì½”ë”© ì™„ë£Œ, ê¸¸ì´:', decodedData.length);

              const uint8Array = Uint8Array.from(decodedData, c => c.charCodeAt(0));
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - Uint8Array ìƒì„± ì™„ë£Œ, ê¸¸ì´:', uint8Array.length);

              // ìŒì„± ì¬ìƒì´ ì‹¤ì œë¡œ ì‹œì‘ë  ë•Œë§Œ ìƒíƒœ ë³€ê²½
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ìŒì„± ì¬ìƒ ì‹œì‘, ìƒíƒœ ë³€ê²½');
              setCurrentState('speaking');
              setDisplayedText(aiResponseText);

              // Base64 ë°ì´í„°ë¥¼ ì§ì ‘ data URIë¡œ ì‚¬ìš©í•˜ì—¬ ìŒì„± ì¬ìƒ
              const dataUri = `data:audio/wav;base64,${audioData}`;
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - Data URI ìƒì„± ì™„ë£Œ, ê¸¸ì´:', dataUri.length);

              const { sound: newSound } = await Audio.Sound.createAsync(
                { uri: dataUri },
                { shouldPlay: true }
              );
              setSound(newSound);
              newSound.setOnPlaybackStatusUpdate((status) => {
                if (status.isLoaded && status.didJustFinish) {
                  console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ìŒì„± ì¬ìƒ ì™„ë£Œ');
                  newSound.unloadAsync();
                  setSound(null);
                  setCurrentState('idle');
                  setDisplayedText('');
                  setAiResponseText('');
                }
              });

            } catch (audioError) {
              console.error('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ìŒì„± ì¬ìƒ ì˜¤ë¥˜:', audioError);
              setCurrentState('idle');
              setDisplayedText('');
              setAiResponseText('');
            }
          } else {
            console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ, ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì²˜ë¦¬');
            // 3ì´ˆ í›„ ìë™ìœ¼ë¡œ idle ìƒíƒœë¡œ ë³µê·€ (ìŒì„± ì¬ìƒ ì™„ë£Œ ì‹œë®¬ë ˆì´ì…˜)
            setTimeout(() => {
              console.log('[ìŒì„±ì±„íŒ…] ë””ë²„ê·¸ ëª¨ë“œ - ìŒì„± ì¬ìƒ ì™„ë£Œ ì‹œë®¬ë ˆì´ì…˜');
              setCurrentState('idle');
              setDisplayedText('');
              setAiResponseText('');
            }, 3000);
          }

          return; // ë””ë²„ê·¸ ëª¨ë“œì—ì„œëŠ” ì—¬ê¸°ì„œ ì¢…ë£Œ
        }
        
        // í”„ë¡œë•ì…˜ ëª¨ë“œ: í´ë§ ë°©ì‹ìœ¼ë¡œ ë¹ ë¥´ê²Œ ìƒíƒœ í™•ì¸ (0.3ì´ˆë§ˆë‹¤)
        let checkStatus: any = null;
        let timeoutId: any = null;
        
        const startPolling = () => {
          // ê¸°ì¡´ í´ë§ì´ ìˆë‹¤ë©´ ì¤‘ì§€
          if (checkStatus) {
            clearInterval(checkStatus);
            checkStatus = null;
          }
          
          // ê¸°ì¡´ íƒ€ì„ì•„ì›ƒì´ ìˆë‹¤ë©´ ì¤‘ì§€
          if (timeoutId) {
            clearTimeout(timeoutId);
            timeoutId = null;
          }
          
          checkStatus = setInterval(async () => {
            try {
              const { data: jobData, error: jobError } = await supabase
                .from('voice_processing_jobs')
                .select('status, audio_url, error_message')
                .eq('job_id', jobId)
                .single();
              
              if (jobError) {
                console.error('[ìŒì„±ì±„íŒ…] ì‘ì—… ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', jobError);
                return;
              }
              
              console.log('[ìŒì„±ì±„íŒ…] ì‘ì—… ìƒíƒœ í™•ì¸ ì¤‘:', jobData.status);
              
              if (jobData.status === 'completed' && jobData.audio_url) {
                console.log('[ìŒì„±ì±„íŒ…] ë“œë””ì–´ ìŒì„± ìƒì„± ì™„ë£Œ!', jobData.audio_url);
                
                // í´ë§ê³¼ íƒ€ì„ì•„ì›ƒ ëª¨ë‘ ì¤‘ì§€
                if (checkStatus) {
                  clearInterval(checkStatus);
                  checkStatus = null;
                }
                if (timeoutId) {
                  clearTimeout(timeoutId);
                  timeoutId = null;
                }
                
                // 6. ì˜¤ë””ì˜¤ URLì„ ì‚¬ìš©í•˜ì—¬ ìŒì„± ì¬ìƒ
                try {
                  if (sound) {
                    await sound.unloadAsync();
                  }
                  
                  // ìŒì„± ì¬ìƒ ì‹œì‘ ì‹œ ìƒíƒœ ë³€ê²½
                  setCurrentState('speaking'); // "ë§í•˜ê³  ìˆì–´ìš”" ìƒíƒœ
                  setDisplayedText(aiResponseText); // AI ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ subtitleì— í‘œì‹œ
                  
                  const { sound: newSound } = await Audio.Sound.createAsync(
                    { uri: jobData.audio_url },
                    { shouldPlay: true }
                  );
                  
                  setSound(newSound);
                  newSound.setOnPlaybackStatusUpdate((status) => {
                    if (status.isLoaded && status.didJustFinish) {
                      console.log('[ìŒì„±ì±„íŒ…] ìŒì„± ì¬ìƒ ì™„ë£Œ');
                      newSound.unloadAsync();
                      setSound(null);
                      setCurrentState('idle');
                      setDisplayedText(''); // í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                      setAiResponseText(''); // AI ì‘ë‹µ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                    }
                  });
                  
                } catch (audioError) {
                  console.error('[ìŒì„±ì±„íŒ…] ìŒì„± ì¬ìƒ ì‹¤íŒ¨:', audioError);
                  setCurrentState('idle');
                  setDisplayedText('');
                  setAiResponseText('');
                }
                
              } else if (jobData.status === 'failed') {
                console.error('[ìŒì„±ì±„íŒ…] ìŒì„± ìƒì„± ì‹¤íŒ¨:', jobData.error_message);
                
                // í´ë§ê³¼ íƒ€ì„ì•„ì›ƒ ëª¨ë‘ ì¤‘ì§€
                if (checkStatus) {
                  clearInterval(checkStatus);
                  checkStatus = null;
                }
                if (timeoutId) {
                  clearTimeout(timeoutId);
                  timeoutId = null;
                }
                
                setDisplayedText('ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
                setCurrentState('error');
              }
              
            } catch (checkError) {
              console.error('[ìŒì„±ì±„íŒ…] ì‘ì—… ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜:', checkError);
              
              // ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ í´ë§ê³¼ íƒ€ì„ì•„ì›ƒ ëª¨ë‘ ì¤‘ì§€
              if (checkStatus) {
                clearInterval(checkStatus);
                checkStatus = null;
              }
              if (timeoutId) {
                clearTimeout(timeoutId);
                timeoutId = null;
              }
            }
          }, 300);
          
          // 10ì´ˆ í›„ì—ë„ ì™„ë£Œë˜ì§€ ì•Šìœ¼ë©´ íƒ€ì„ì•„ì›ƒ
          timeoutId = setTimeout(() => {
            if (checkStatus) {
              clearInterval(checkStatus);
              checkStatus = null;
            }
            console.log('[ìŒì„±ì±„íŒ…] ìŒì„± ìƒì„± íƒ€ì„ì•„ì›ƒ');
          }, 10000);
        };
        
        // í´ë§ ì‹œì‘
        startPolling();
        
      } catch (finishError) {
        console.error('[ìŒì„±ì±„íŒ…] ai-voice-finish ì²˜ë¦¬ ì‹¤íŒ¨:', finishError);
        setDisplayedText('ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        setCurrentState('error');
      }
      
    } catch (error) {
      console.error('[ìŒì„±ì±„íŒ…] ìƒˆë¡œìš´ ë¹„ë™ê¸° ë°©ì‹ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      setCurrentState('error');
      setDisplayedText('ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  }, [addMessageToHistory, sound, sessionId, sessionStartTime, mode, currentStep, shouldEnableStepProgression, isDebugMode, isNewGoal, conversationMemory]);



  // --- Audio Playback Logic (ê¸°ì¡´ê³¼ ë™ì¼) ---
  const playAudio = useCallback(async (base64Data: string, onFinish: () => void) => {
    try {
      if (sound) {
        await sound.unloadAsync();
      }
      const { sound: newSound } = await Audio.Sound.createAsync(
        { uri: `data:audio/mp3;base64,${base64Data}` },
        { shouldPlay: true }
      );
      setSound(newSound);
      newSound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          onFinish();
          newSound.unloadAsync();
          setSound(null);
        }
      });
    } catch (error) {
      console.error('[ìŒì„±ì±„íŒ…] ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error);
      onFinish();
    }
  }, [sound]);

  useEffect(() => {
    const playNextInQueue = async () => {
      if (audioQueue.length > 0 && !isPlayingAudio) {
        setIsPlayingAudio(true);
        const nextAudioChunk = audioQueue[0];
        await playAudio(nextAudioChunk, () => {
          setAudioQueue(prev => prev.slice(1));
          setIsPlayingAudio(false);
        });
      }
    };
    playNextInQueue();
  }, [audioQueue, isPlayingAudio, playAudio]);

  // --- Recording Logic (ê¸°ì¡´ê³¼ ë™ì¼) ---
  
  // ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
  const testMicrophone = async () => {
    try {
      console.log('[ë§ˆì´í¬ í…ŒìŠ¤íŠ¸] ì‹œì‘...');
      setDisplayedText('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì¤‘...');
      
      // 1. ê¶Œí•œ í™•ì¸
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        setDisplayedText('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•´ìš”!');
        return;
      }
      
      // 2. ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì •
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        interruptionModeAndroid: InterruptionModeAndroid.DoNotMix,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
        staysActiveInBackground: false,
      });
      
      // 3. í…ŒìŠ¤íŠ¸ ë…¹ìŒ ì‹œì‘ (3ì´ˆ)
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );
      
      let maxMetering = -100;
      let hasAudioSignal = false;
      
      recording.setOnRecordingStatusUpdate((status) => {
        if (status.isRecording) {
          console.log('[ë§ˆì´í¬ í…ŒìŠ¤íŠ¸] ë…¹ìŒ ì¤‘...', {
            metering: status.metering,
            duration: status.durationMillis
          });
          
          if (status.metering && status.metering > maxMetering) {
            maxMetering = status.metering;
          }
          
          if (status.metering && status.metering > -60) {
            hasAudioSignal = true;
          }
          
          // ì‹¤ì‹œê°„ í”¼ë“œë°±
          if (status.metering && status.metering > -20) {
            setDisplayedText('ğŸ¤ ìŒì„± ë ˆë²¨: ë§¤ìš° ì¢‹ìŒ!');
          } else if (status.metering && status.metering > -40) {
            setDisplayedText('ğŸ¤ ìŒì„± ë ˆë²¨: ì¢‹ìŒ');
          } else if (status.metering && status.metering > -60) {
            setDisplayedText('ğŸ¤ ìŒì„± ë ˆë²¨: ë³´í†µ');
          } else {
            setDisplayedText('ğŸ¤ ìŒì„± ë ˆë²¨: ë‚®ìŒ (ë§ˆì´í¬ í™•ì¸ í•„ìš”)');
          }
        }
        
        if (status.isDoneRecording) {
          console.log('[ë§ˆì´í¬ í…ŒìŠ¤íŠ¸] ì™„ë£Œ!', {
            maxMetering,
            hasAudioSignal,
            duration: status.durationMillis
          });
          
          // ê²°ê³¼ ë¶„ì„
          if (hasAudioSignal && maxMetering > -40) {
            setDisplayedText('âœ… ë§ˆì´í¬ ì •ìƒ ì‘ë™! ìŒì„±ì´ ì˜ ë“¤ë ¤ìš”.');
          } else if (hasAudioSignal) {
            setDisplayedText('âš ï¸ ë§ˆì´í¬ëŠ” ì‘ë™í•˜ì§€ë§Œ ìŒì„±ì´ ì‘ì•„ìš”. ë” í¬ê²Œ ë§í•´ì£¼ì„¸ìš”.');
          } else {
            setDisplayedText('ğŸš¨ ë§ˆì´í¬ì—ì„œ ìŒì„±ì´ ë“¤ë¦¬ì§€ ì•Šì•„ìš”! ë§ˆì´í¬ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
          }
          
          // 3ì´ˆ í›„ ì›ë˜ ìƒíƒœë¡œ ë³µì›
          setTimeout(() => {
            setDisplayedText('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ');
          }, 3000);
        }
      });
      
      // 4. 3ì´ˆ í›„ ìë™ ì •ì§€
      setTimeout(async () => {
        try {
          await recording.stopAndUnloadAsync();
        } catch (err) {
          console.error('[ë§ˆì´í¬ í…ŒìŠ¤íŠ¸] ì •ì§€ ì‹¤íŒ¨:', err);
        }
      }, 3000);
      
    } catch (err) {
      console.error('[ë§ˆì´í¬ í…ŒìŠ¤íŠ¸] ì‹¤íŒ¨:', err);
      setDisplayedText('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆì–´ìš”.');
    }
  };
  
  const startRecording = async () => {
    try {
      console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì‹œì‘ ì¤€ë¹„...');
      
      // 1. ê¶Œí•œ ìš”ì²­ (ë” ê°•ë ¥í•œ ê¶Œí•œ ì²´í¬)
      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        setDisplayedText('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•´ìš”. ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        setCurrentState('error');
        return;
      }
      console.log('[ìŒì„±ì±„íŒ…] ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ë¨');

      // 2. ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì • (ë” ê°•ë ¥í•œ ì„¤ì •)
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        interruptionModeAndroid: InterruptionModeAndroid.DoNotMix,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
        staysActiveInBackground: false,
      });
      console.log('[ìŒì„±ì±„íŒ…] ì˜¤ë””ì˜¤ ëª¨ë“œ ì„¤ì • ì™„ë£Œ');
      
      // 3. ê³ í’ˆì§ˆ ë…¹ìŒ ì˜µì…˜ ìƒì„± (ë” ë†’ì€ í’ˆì§ˆ + ë§ˆì´í¬ ê°ë„ í–¥ìƒ)
      const recordingOptions = {
        ...Audio.RecordingOptionsPresets.HIGH_QUALITY,
        android: {
          ...Audio.RecordingOptionsPresets.HIGH_QUALITY.android,
          sampleRate: 44100,        // 44.1kHz (CD í’ˆì§ˆ)
          numberOfChannels: 1,      // ëª¨ë…¸
          bitRate: 320000,          // 320kbps (ìµœê³  í’ˆì§ˆ)
          // ë§ˆì´í¬ ê°ë„ í–¥ìƒ ì„¤ì •
          gainControl: 1,           // ìë™ ê²Œì¸ ì»¨íŠ¸ë¡¤ í™œì„±í™”
          echoCancellation: false,  // ì—ì½” ìº”ìŠ¬ë ˆì´ì…˜ ë¹„í™œì„±í™” (ìŒì„± í’ˆì§ˆ í–¥ìƒ)
          noiseSuppression: false,  // ë…¸ì´ì¦ˆ ì„œí”„ë ˆì…˜ ë¹„í™œì„±í™” (ìŒì„± í’ˆì§ˆ í–¥ìƒ)
        },
        ios: {
          ...Audio.RecordingOptionsPresets.HIGH_QUALITY.ios,
          sampleRate: 44100,        // 44.1kHz
          numberOfChannels: 1,      // ëª¨ë…¸
          bitRate: 320000,          // 320kbps
        },
      };
      
      console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì˜µì…˜:', recordingOptions);
      
      // 4. ë…¹ìŒ ì‹œì‘
      const { recording: newRecording } = await Audio.Recording.createAsync(recordingOptions);
      
      // 5. ë…¹ìŒ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì„¤ì • (ë” ìƒì„¸í•œ ëª¨ë‹ˆí„°ë§)
      newRecording.setOnRecordingStatusUpdate((status) => {
        if (status.isRecording) {
          console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì¤‘...', {
            duration: status.durationMillis,
            metering: status.metering,
            isRecording: status.isRecording
          });
          
          // ìŒì„± ë ˆë²¨ì— ë”°ë¥¸ ì‹¤ì‹œê°„ í”¼ë“œë°±
          if (status.metering && status.metering > -20) {
            console.log('âœ… ìŒì„± ë ˆë²¨ ë§¤ìš° ì¢‹ìŒ');
            setDisplayedText('ìŒì„±ì´ ì˜ ë“¤ë¦¬ê³  ìˆì–´ìš”!');
          } else if (status.metering && status.metering > -40) {
            console.log('âœ… ìŒì„± ë ˆë²¨ ì •ìƒ');
            setDisplayedText('ìŒì„±ì´ ë“¤ë¦¬ê³  ìˆì–´ìš”');
          } else if (status.metering && status.metering > -60) {
            console.log('âš ï¸ ìŒì„± ë ˆë²¨ ë‚®ìŒ');
            setDisplayedText('ìŒì„±ì´ ì¡°ê¸ˆ ì‘ì•„ìš”. ë” í¬ê²Œ ë§í•´ì£¼ì„¸ìš”.');
          } else if (status.metering && status.metering < -60) {
            console.warn('ğŸš¨ ìŒì„± ë ˆë²¨ ë§¤ìš° ë‚®ìŒ - ë§ˆì´í¬ ë¬¸ì œ ê°€ëŠ¥ì„±');
            setDisplayedText('ìŒì„±ì´ ë“¤ë¦¬ì§€ ì•Šì•„ìš”! ë§ˆì´í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.');
          }
        }
        
        if (status.isDoneRecording) {
          console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì™„ë£Œ!', {
            duration: status.durationMillis
          });
        }
      });
      
      setRecording(newRecording);
      setCurrentState('listening');
      setDisplayedText('ë§ì”€í•´ì£¼ì„¸ìš”...');
      console.log('[ìŒì„±ì±„íŒ…] ìµœê³ í’ˆì§ˆ ë…¹ìŒ ì‹œì‘ ì™„ë£Œ! (44.1kHz, 320kbps)');

    } catch (err) {
      console.error('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', err);
      setCurrentState('error');
      setDisplayedText('ë…¹ìŒ ì‹œì‘ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopRecordingAndSend = async () => {
    if (!recording) {
      console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì¤‘ì§€ ë° ì „ì†¡ ì‹œì‘...');
    setCurrentState('processing');
    setDisplayedText('');
    fullResponseTextRef.current = '';

    try {
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      setRecording(null); // Clear the recording state

      if (!uri) {
        throw new Error('ë…¹ìŒëœ íŒŒì¼ì˜ URIë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }

      console.log('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì™„ë£Œ, URI:', uri);
      const base64Audio = await FileSystem.readAsStringAsync(uri, {
        encoding: FileSystem.EncodingType.Base64,
      });

      // ìƒˆë¡œìš´ ë¹„ë™ê¸° ë°©ì‹ ì‚¬ìš© (í”„ë¡¬í”„íŠ¸ ì œê±°ë¡œ ìµœì í™”)
      await processVoiceWithNewAsyncMethod(base64Audio);

    } catch (error) {
      console.error('[ìŒì„±ì±„íŒ…] ë…¹ìŒ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      setCurrentState('error');
      setDisplayedText('ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  };

  // --- Session and UI Logic ---
  const handleMainAreaPress = useCallback(() => {
    Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Medium);
    if (recording) {
      stopRecordingAndSend();
    } else if (currentState === 'idle' || currentState === 'error') {
      startRecording();
    }
  }, [recording, currentState]);

  const cleanUp = useCallback(async () => {
    console.log('[ìŒì„±ì±„íŒ…] ì •ë¦¬ ì‘ì—… ìˆ˜í–‰...');
    if (recording) {
      await recording.stopAndUnloadAsync().catch(e => console.error("ì •ë¦¬ ì¤‘ ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜:", e));
      setRecording(null);
    }
    if (sound) {
      await sound.unloadAsync().catch(e => console.error("ì •ë¦¬ ì¤‘ ì‚¬ìš´ë“œ ë¡œë“œ ì˜¤ë¥˜:", e));
      setSound(null);
    }
    // Reset audio mode
    await Audio.setAudioModeAsync({
        allowsRecordingIOS: false,
    }).catch(e => console.error("ì •ë¦¬ ì¤‘ ì˜¤ë””ì˜¤ ëª¨ë“œ ë¦¬ì…‹ ì˜¤ë¥˜:", e));
  }, [recording, sound]);

  useEffect(() => {
    if (visible) {
      fadeAnim.value = withTiming(1);
      scaleAnim.value = withSpring(1);
      textFadeAnim.value = withTiming(1);
      setCurrentState('idle');
    } else {
      fadeAnim.value = withTiming(0);
      scaleAnim.value = withTiming(0.8);
      textFadeAnim.value = withTiming(0);
      cleanUp();
    }
  }, [visible]);

  // AppState listener
  useEffect(() => {
    const subscription = AppState.addEventListener('change', (nextAppState) => {
      if (nextAppState.match(/inactive|background/)) {
        cleanUp();
      }
    });
    return () => {
      subscription.remove();
    };
  }, [cleanUp]);

  const handleClose = useCallback(() => {
    cleanUp().then(() => onClose());
  }, [cleanUp, onClose]);

  const modalStyle = useAnimatedStyle(() => ({ opacity: fadeAnim.value, transform: [{ scale: scaleAnim.value }] }));
  const textStyle = useAnimatedStyle(() => ({ opacity: textFadeAnim.value }));
  const styles = createStyles(colors);
  const config = VOICE_STATE_CONFIG[currentState] || VOICE_STATE_CONFIG.idle;

  return (
    <Modal visible={visible} transparent={true} animationType="none" onRequestClose={handleClose} statusBarTranslucent={true}>
      <StatusBar barStyle="light-content" />
      <Animated.View style={[styles.modalContainer, modalStyle]}>
        <SafeAreaView style={styles.safeArea}>
          {/* Step progress UI can be kept as is */}
          <TouchableOpacity style={styles.mainArea} onPress={handleMainAreaPress} activeOpacity={0.95}>
            <Animated.View style={[styles.statusContainer, textStyle]}>
              <Text style={[styles.titleText, koreanTextStyle(config.title)]}>{config.title}</Text>
              <Text style={[styles.subtitleText, koreanTextStyle(displayedText || config.subtitle)]}>
                {currentState === 'speaking' ? aiResponseText : (displayedText || config.subtitle)}
              </Text>
            </Animated.View>
            <View style={styles.visualizerContainer}>
              <VoiceVisualizer state={isPaused ? 'idle' : currentState} />
            </View>
          </TouchableOpacity>
          <VoiceChatControls onPause={() => setIsPaused(true)} onResume={() => setIsPaused(false)} isPaused={isPaused} />
          
          <TouchableOpacity style={styles.reportButton} onPress={onSwitchToText || handleClose}>
            <MaterialIcons name="description" size={35} color={colors.text} />
          </TouchableOpacity>
        </SafeAreaView>
      </Animated.View>
    </Modal>
  );
};

// --- Styles remain the same ---
const createStyles = (colors: typeof Colors.light) => StyleSheet.create({
  modalContainer: { flex: 1, backgroundColor: colors.background },
  safeArea: { flex: 1 },
  mainArea: { flex: 1, justifyContent: 'center', alignItems: 'center', paddingHorizontal: Spacing.screen.paddingHorizontal },
  statusContainer: { position: 'absolute', top: 120, alignItems: 'center', width: '100%', backgroundColor: colors.card, borderRadius: Spacing.layout.borderRadius.lg, paddingVertical: 24, paddingHorizontal: Spacing.xl, marginHorizontal: Spacing.lg },
  titleText: { fontSize: 50, fontWeight: '600', color: colors.text, marginBottom: Spacing.sm, textAlign: 'center' },
  subtitleText: { fontSize: 25, color: colors.textSecondary, textAlign: 'center', marginBottom: Spacing.sm, paddingHorizontal: Spacing.lg, lineHeight: 25 * 1.5 },
  visualizerContainer: { flex: 1, justifyContent: 'center', alignItems: 'center', width: '100%', maxHeight: 400, marginTop: Spacing['6xl'] },
  reportButton: { position: 'absolute', bottom: 40, right: 24, width: 96, height: 96, borderRadius: 48, backgroundColor: colors.surface, borderWidth: 1, borderColor: colors.border, justifyContent: 'center', alignItems: 'center', shadowColor: '#000', shadowOffset: { width: 0, height: 2 }, shadowOpacity: 0.1, shadowRadius: 4, elevation: 3 },
  stepProgressContainer: { paddingTop: Spacing['7xl'], paddingHorizontal: Spacing.screen.paddingHorizontal, paddingBottom: Spacing.md, backgroundColor: colors.background },
  stepIndicatorContainer: { alignItems: 'center', marginBottom: Spacing.md },
  stepIndicatorText: { fontSize: 16, fontWeight: 'bold', color: colors.textSecondary, textAlign: 'center', marginBottom: Spacing.xs },
  stepDescriptionText: { fontSize: 14, fontWeight: '500', color: colors.textSecondary, textAlign: 'center', opacity: 0.8 },
  progressBarContainer: { height: 4, backgroundColor: colors.surface, borderRadius: 2, overflow: 'hidden', marginHorizontal: Spacing.lg },
  progressBarFill: { height: '100%', backgroundColor: colors.primary, borderRadius: 2 },
  testButton: { flexDirection: 'row', alignItems: 'center', backgroundColor: colors.surface, borderRadius: Spacing.layout.borderRadius.md, paddingVertical: Spacing.sm, paddingHorizontal: Spacing.md, marginTop: Spacing.md, marginBottom: Spacing.md, borderWidth: 1, borderColor: colors.border },
  testButtonText: { fontSize: 16, fontWeight: '500', color: colors.text, marginLeft: Spacing.sm },
  micStatusContainer: {
    position: 'absolute',
    bottom: 100,
    backgroundColor: colors.surface,
    borderRadius: Spacing.layout.borderRadius.md,
    paddingVertical: Spacing.sm,
    paddingHorizontal: Spacing.md,
    borderWidth: 1,
    borderColor: colors.border,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  micStatusText: {
    fontSize: 18,
    fontWeight: 'bold',
    color: colors.text,
    marginBottom: Spacing.xs,
  },
  micStatusSubtext: {
    fontSize: 14,
    color: colors.textSecondary,
    textAlign: 'center',
  },

});

export default VoiceChatScreen;